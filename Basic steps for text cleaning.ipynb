{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics steps for cleaning text data\n",
    "  1. Removing the punctuation\n",
    "  2. Upper or lower case conversion\n",
    "  3. Removing the stopwords. (a, an, the.....)\n",
    "  4. Removing unwanted text ('/n','/x'....)\n",
    "  5. Tokenization (Word tokenization, sentance tokenization-----> eg. Hii I am hari---->op:seperate words in vertical)\n",
    "  6. Lematization and stemming (stemming is converting word to root word. Might not have meaning to the word---< eg:playing---play >)\n",
    "                               (Lematization gives meaningful word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced text cleaning steps:\n",
    "  1. Normalization (mapping short word to meaningful word eg-tc - takecare)\n",
    "  2. Correction of typoes (mapping wrong input word to correct word with help of dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"!But, even   though it seems like there aren’t any rules when it comes to writing a text message\", \n",
    "\"there are some unspoken general guidelines—especially when    it comes to punctuation. Do you include a period at the end of a sentence?\", \n",
    "\"Can you use a smiley face emoji as a period instead?\", \n",
    "\"The answers to these questions—and many more—will vary. If you’re talking to your coworker, maybe leave out the snarky periods.\" ,\n",
    "\"But your friends will likely appreciate some creative emoji game to end a witty comment ?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=nltk.WordNetLemmatizer()\n",
    "\n",
    "def text_clean(text):\n",
    "    \n",
    "    # removing punctuation and unwanted words in text\n",
    "    text = re.sub(\"[^A-Za-z0-9]\",\" \",text)\n",
    "    \n",
    "    # Lower case\n",
    "    text = \"\".join([i.lower() for i in text])\n",
    "    \n",
    "    # tokenize\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    # stopwords\n",
    "    text = [i for i in text if i not in stopwords.words('english')]\n",
    "    \n",
    "    # Lematizer\n",
    "    text = [lm.lemmatize(i) for i in text]\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['even',\n",
       " 'though',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'rule',\n",
       " 'come',\n",
       " 'writing',\n",
       " 'text',\n",
       " 'message',\n",
       " 'unspoken',\n",
       " 'general',\n",
       " 'guideline',\n",
       " 'especially',\n",
       " 'come',\n",
       " 'punctuation',\n",
       " 'include',\n",
       " 'period',\n",
       " 'end',\n",
       " 'sentence',\n",
       " 'use',\n",
       " 'smiley',\n",
       " 'face',\n",
       " 'emoji',\n",
       " 'period',\n",
       " 'instead',\n",
       " 'answer',\n",
       " 'question',\n",
       " 'many',\n",
       " 'vary',\n",
       " 'talking',\n",
       " 'coworker',\n",
       " 'maybe',\n",
       " 'leave',\n",
       " 'snarky',\n",
       " 'period',\n",
       " 'friend',\n",
       " 'likely',\n",
       " 'appreciate',\n",
       " 'creative',\n",
       " 'emoji',\n",
       " 'game',\n",
       " 'end',\n",
       " 'witty',\n",
       " 'comment']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 --- Removing extra space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time the text data that you have may contain extra spaces in between the words, after or before a sentence. So to start with we will remove these extra spaces from each sentence by using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['!But, even though it seems like there aren’t any rules when it comes to writing a text message', 'there are some unspoken general guidelines—especially when it comes to punctuation. Do you include a period at the end of a sentence?', 'Can you use a smiley face emoji as a period instead?', 'The answers to these questions—and many more—will vary. If you’re talking to your coworker, maybe leave out the snarky periods.', 'But your friends will likely appreciate some creative emoji game to end a witty comment ?']\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"\".join(re.sub(\"\\s+\",\" \",text))  # used to remove extra white spaces\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 --- Removing punctution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The punctuations present in the text do not add value to the data. The punctuation, when attached to any word, will create a problem in differentiating with other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hii.\" == \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hi\" == \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' but  even   though it seems like there aren t any rules when it comes to writing a text messagethere are some unspoken general guidelines especially when    it comes to punctuation  do you include a period at the end of a sentence can you use a smiley face emoji as a period instead the answers to these questions and many more will vary  if you re talking to your coworker  maybe leave out the snarky periods but your friends will likely appreciate some creative emoji game to end a witty comment  '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\".join(re.sub(\"[^0-9A-Za-z]\",\" \", text))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 --- Case Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this, we simply convert the case of all characters in the text to either upper or lower case. As python is a case sensitive language so it will treat NLP and nlp differently. One can easily convert the string to either lower or upper by using:\n",
    "str.lower() or str.upper()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['!but, even   though it seems like there aren’t any rules when it comes to writing a text message', 'there are some unspoken general guidelines—especially when    it comes to punctuation. do you include a period at the end of a sentence?', 'can you use a smiley face emoji as a period instead?', 'the answers to these questions—and many more—will vary. if you’re talking to your coworker, maybe leave out the snarky periods.', 'but your friends will likely appreciate some creative emoji game to end a witty comment ?']\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"\".join([i.lower() for i in text])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 --- Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting a sentence into words and creating a list, ie each sentence is a list of words. There are mainly 3 types of tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['but',\n",
       " 'even',\n",
       " 'though',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'there',\n",
       " 'aren',\n",
       " 't',\n",
       " 'any',\n",
       " 'rules',\n",
       " 'when',\n",
       " 'it',\n",
       " 'comes',\n",
       " 'to',\n",
       " 'writing',\n",
       " 'a',\n",
       " 'text',\n",
       " 'messagethere',\n",
       " 'are',\n",
       " 'some',\n",
       " 'unspoken',\n",
       " 'general',\n",
       " 'guidelines',\n",
       " 'especially',\n",
       " 'when',\n",
       " 'it',\n",
       " 'comes',\n",
       " 'to',\n",
       " 'punctuation',\n",
       " 'do',\n",
       " 'you',\n",
       " 'include',\n",
       " 'a',\n",
       " 'period',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'a',\n",
       " 'sentence',\n",
       " 'can',\n",
       " 'you',\n",
       " 'use',\n",
       " 'a',\n",
       " 'smiley',\n",
       " 'face',\n",
       " 'emoji',\n",
       " 'as',\n",
       " 'a',\n",
       " 'period',\n",
       " 'instead',\n",
       " 'the',\n",
       " 'answers',\n",
       " 'to',\n",
       " 'these',\n",
       " 'questions',\n",
       " 'and',\n",
       " 'many',\n",
       " 'more',\n",
       " 'will',\n",
       " 'vary',\n",
       " 'if',\n",
       " 'you',\n",
       " 're',\n",
       " 'talking',\n",
       " 'to',\n",
       " 'your',\n",
       " 'coworker',\n",
       " 'maybe',\n",
       " 'leave',\n",
       " 'out',\n",
       " 'the',\n",
       " 'snarky',\n",
       " 'periods',\n",
       " 'but',\n",
       " 'your',\n",
       " 'friends',\n",
       " 'will',\n",
       " 'likely',\n",
       " 'appreciate',\n",
       " 'some',\n",
       " 'creative',\n",
       " 'emoji',\n",
       " 'game',\n",
       " 'to',\n",
       " 'end',\n",
       " 'a',\n",
       " 'witty',\n",
       " 'comment']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tok=word_tokenize(text)\n",
    "word_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 --- Removing stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords include: I, he, she, and, but, was were, being, have, etc, which do not add meaning to the data. So these words must be removed which helps to reduce the features from our data. These are removed after tokenizing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['even',\n",
       " 'though',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'rules',\n",
       " 'comes',\n",
       " 'writing',\n",
       " 'text',\n",
       " 'messagethere',\n",
       " 'unspoken',\n",
       " 'general',\n",
       " 'guidelines',\n",
       " 'especially',\n",
       " 'comes',\n",
       " 'punctuation',\n",
       " 'include',\n",
       " 'period',\n",
       " 'end',\n",
       " 'sentence',\n",
       " 'use',\n",
       " 'smiley',\n",
       " 'face',\n",
       " 'emoji',\n",
       " 'period',\n",
       " 'instead',\n",
       " 'answers',\n",
       " 'questions',\n",
       " 'many',\n",
       " 'vary',\n",
       " 'talking',\n",
       " 'coworker',\n",
       " 'maybe',\n",
       " 'leave',\n",
       " 'snarky',\n",
       " 'periods',\n",
       " 'friends',\n",
       " 'likely',\n",
       " 'appreciate',\n",
       " 'creative',\n",
       " 'emoji',\n",
       " 'game',\n",
       " 'end',\n",
       " 'witty',\n",
       " 'comment']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st=[i for i in word_tok if i not in stopwords.words('english')]\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 --- Lematization and stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Stemming: A technique that takes the word to its root form. It just removes suffixes from the words. The stemmed word might not be part of the dictionary, i.e it will not necessarily give meaning. There are two main types of stemmer- Porter Stemmer and Snow Ball Stemmer(advanced version of Porter Stemmer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Lemmatization: Takes the word to its root form called Lemma. It helps to bring words to their dictionary form. It is applied to nouns by default. It is more accurate as it uses more informed analysis to create groups of words with similar meanings based on the context, so it is complex and takes more time. This is used where we need to retain the contextual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['even',\n",
       " 'though',\n",
       " 'seem',\n",
       " 'like',\n",
       " 'rule',\n",
       " 'come',\n",
       " 'write',\n",
       " 'text',\n",
       " 'messagether',\n",
       " 'unspoken',\n",
       " 'gener',\n",
       " 'guidelin',\n",
       " 'especi',\n",
       " 'come',\n",
       " 'punctuat',\n",
       " 'includ',\n",
       " 'period',\n",
       " 'end',\n",
       " 'sentenc',\n",
       " 'use',\n",
       " 'smiley',\n",
       " 'face',\n",
       " 'emoji',\n",
       " 'period',\n",
       " 'instead',\n",
       " 'answer',\n",
       " 'question',\n",
       " 'mani',\n",
       " 'vari',\n",
       " 'talk',\n",
       " 'cowork',\n",
       " 'mayb',\n",
       " 'leav',\n",
       " 'snarki',\n",
       " 'period',\n",
       " 'friend',\n",
       " 'like',\n",
       " 'appreci',\n",
       " 'creativ',\n",
       " 'emoji',\n",
       " 'game',\n",
       " 'end',\n",
       " 'witti',\n",
       " 'comment']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm=nltk.PorterStemmer()\n",
    "sm=[sm.stem(i) for i in st]\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['even',\n",
       " 'though',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'rule',\n",
       " 'come',\n",
       " 'writing',\n",
       " 'text',\n",
       " 'messagethere',\n",
       " 'unspoken',\n",
       " 'general',\n",
       " 'guideline',\n",
       " 'especially',\n",
       " 'come',\n",
       " 'punctuation',\n",
       " 'include',\n",
       " 'period',\n",
       " 'end',\n",
       " 'sentence',\n",
       " 'use',\n",
       " 'smiley',\n",
       " 'face',\n",
       " 'emoji',\n",
       " 'period',\n",
       " 'instead',\n",
       " 'answer',\n",
       " 'question',\n",
       " 'many',\n",
       " 'vary',\n",
       " 'talking',\n",
       " 'coworker',\n",
       " 'maybe',\n",
       " 'leave',\n",
       " 'snarky',\n",
       " 'period',\n",
       " 'friend',\n",
       " 'likely',\n",
       " 'appreciate',\n",
       " 'creative',\n",
       " 'emoji',\n",
       " 'game',\n",
       " 'end',\n",
       " 'witty',\n",
       " 'comment']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm=nltk.WordNetLemmatizer()\n",
    "lm=[lm.lemmatize(i) for i in st]\n",
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
